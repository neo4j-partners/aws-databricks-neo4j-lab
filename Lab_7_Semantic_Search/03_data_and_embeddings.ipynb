{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-01",
   "metadata": {},
   "source": "# Aircraft Maintenance Manual - Data Loading and Embeddings\n\nThis notebook covers the complete data preparation pipeline for adding semantic search capabilities to your aircraft knowledge graph. We'll load the A320-200 Maintenance Manual into Neo4j as a Document-Chunk structure, then enrich it with embeddings for semantic search.\n\n**Prerequisites:**\n- Complete **Lab 5** (Databricks ETL) to load the aircraft topology graph (Aircraft, System, Component nodes)\n- Running in a Databricks notebook environment\n\n**Learning Objectives:**\n- Understand the Document -> Chunk graph structure for semantic search\n- Connect to Neo4j and create Document and Chunk nodes alongside existing aircraft data\n- Link chunks with `FROM_DOCUMENT` and `NEXT_CHUNK` relationships\n- Generate embeddings using Databricks Foundation Model APIs (BGE-large)\n- Create a vector index and perform similarity search over maintenance procedures\n\n---\n\n## Why Documents and Chunks?\n\nWhen building GraphRAG applications, we split documents into smaller pieces called **chunks** because:\n\n1. **Context windows are limited** - LLMs can only process a certain amount of text at once\n2. **Retrieval precision** - Smaller chunks allow more precise matching to user queries\n3. **Cost efficiency** - Processing smaller chunks is faster and cheaper\n\nThe graph structure we'll build extends your existing aircraft topology:\n```\n(:Aircraft)-[:HAS_SYSTEM]->(:System)-[:HAS_COMPONENT]->(:Component)\n                                |\n(:Document) <-[:FROM_DOCUMENT]- (:Chunk) -[:NEXT_CHUNK]-> (:Chunk)\n```\n\nThe maintenance manual chunks can later be linked to specific aircraft, systems, or components for graph-enhanced retrieval."
  },
  {
   "cell_type": "markdown",
   "id": "setup-01",
   "metadata": {},
   "source": "## Section 1: Configuration\n\nEnter your Neo4j Aura connection details below. You received these credentials when you created your Neo4j Aura instance in Lab 1."
  },
  {
   "cell_type": "code",
   "id": "x22pt2efnx",
   "source": "# ============================================\n# CONFIGURATION - Enter your Neo4j credentials\n# ============================================\n\nNEO4J_URI = \"\"  # e.g., \"neo4j+s://xxxxxxxx.databases.neo4j.io\"\nNEO4J_USERNAME = \"neo4j\"\nNEO4J_PASSWORD = \"\"  # Your password from Lab 1\n\n# Unity Catalog Volume path (pre-configured by workshop admin)\nDATA_PATH = \"/Volumes/aws-databricks-neo4j-lab/lab-schema/lab-volume\"\n\n# Validate configuration\nif not NEO4J_URI or not NEO4J_PASSWORD:\n    print(\"WARNING: Please enter your Neo4j credentials above before running the notebook!\")\nelse:\n    print(\"Configuration ready!\")\n    print(f\"Neo4j URI: {NEO4J_URI}\")\n    print(f\"Data Path: {DATA_PATH}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "u6ryvqpejld",
   "source": "## Setup\n\nImport required modules and configure the environment.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-01",
   "metadata": {},
   "outputs": [],
   "source": "from neo4j_graphrag.indexes import create_vector_index, create_fulltext_index, upsert_vectors\nfrom data_utils import (\n    Neo4jConnection, VolumeDataLoader, split_text, get_embedder,\n    EMBEDDING_DIMENSIONS\n)"
  },
  {
   "cell_type": "markdown",
   "id": "data-intro-01",
   "metadata": {},
   "source": "## Maintenance Manual Data\n\nWe'll load the A320-200 Maintenance and Troubleshooting Manual from the Unity Catalog Volume. This file was uploaded during lab setup along with the aircraft CSV data.\n\n**Volume Path:** `/Volumes/aws-databricks-neo4j-lab/lab-schema/lab-volume/MAINTENANCE_A320.md`\n\nThis comprehensive document includes:\n\n- **Aircraft specifications** for the SkyWays A320-200 fleet (5 aircraft)\n- **System architecture** covering Engines (V2500-A1), Avionics, and Hydraulics\n- **Troubleshooting procedures** with fault codes and decision trees\n- **Operating limits** and scheduled maintenance tasks\n\nThis realistic maintenance manual will allow semantic search queries like:\n- \"How do I troubleshoot engine vibration?\"\n- \"What are the EGT limits during takeoff?\"\n- \"What causes hydraulic pressure loss?\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data-01",
   "metadata": {},
   "outputs": [],
   "source": "# Load text from the maintenance manual in Unity Catalog Volume\nloader = VolumeDataLoader(\"MAINTENANCE_A320.md\", volume_path=DATA_PATH)\nMANUAL_TEXT = loader.text\n\n# Document metadata\nDOCUMENT_ID = \"AMM-A320-2024-001\"\nDOCUMENT_TYPE = \"Maintenance Manual\"\nAIRCRAFT_TYPE = \"A320-200\"\n\nmetadata = loader.get_metadata()\nprint(f\"Loaded: {metadata['name']}\")\nprint(f\"From Volume: {metadata['volume']}\")\nprint(f\"Size: {metadata['size']:,} characters\")\nprint(f\"\\nFirst 500 characters:\")\nprint(f\"{MANUAL_TEXT[:500]}...\")"
  },
  {
   "cell_type": "markdown",
   "id": "neo4j-connect-01",
   "metadata": {},
   "source": [
    "## Connect to Neo4j\n",
    "\n",
    "Create a connection to your Neo4j database. This should already contain the aircraft topology from Lab 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connect-01",
   "metadata": {},
   "outputs": [],
   "source": "neo4j = Neo4jConnection(uri=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD).verify()\ndriver = neo4j.driver\n\n# Show existing graph statistics\nneo4j.get_graph_stats()"
  },
  {
   "cell_type": "markdown",
   "id": "clear-data-01",
   "metadata": {},
   "source": [
    "## Clear Existing Chunks (Optional)\n",
    "\n",
    "For a clean start, remove any existing Document and Chunk nodes from previous runs. This preserves your aircraft topology (Aircraft, System, Component nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-01",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j.clear_chunks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Building the Document-Chunk Graph\n",
    "\n",
    "First, we'll create the basic graph structure with Document and Chunk nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-doc-intro",
   "metadata": {},
   "source": [
    "## Create Document Node\n",
    "\n",
    "Create a Document node to represent the maintenance manual. This node stores metadata about the document including its ID, type, and applicable aircraft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-doc-01",
   "metadata": {},
   "outputs": [],
   "source": "def create_document(driver, doc_id: str, doc_type: str, aircraft_type: str) -> str:\n    \"\"\"Create a Document node and return its element ID.\"\"\"\n    records, _, _ = driver.execute_query(\"\"\"\n        CREATE (d:Document {\n            documentId: $doc_id,\n            type: $doc_type,\n            aircraftType: $aircraft_type,\n            title: 'A320-200 Maintenance and Troubleshooting Manual'\n        })\n        RETURN elementId(d) as doc_id\n    \"\"\", doc_id=doc_id, doc_type=doc_type, aircraft_type=aircraft_type)\n    return records[0][\"doc_id\"]\n\ndoc_element_id = create_document(driver, DOCUMENT_ID, DOCUMENT_TYPE, AIRCRAFT_TYPE)\nprint(f\"Created Document node with ID: {doc_element_id}\")"
  },
  {
   "cell_type": "markdown",
   "id": "split-intro",
   "metadata": {},
   "source": [
    "## Split Text into Chunks\n",
    "\n",
    "Use `FixedSizeSplitter` from neo4j-graphrag-python to split the manual into chunks. For technical documentation:\n",
    "\n",
    "- `chunk_size=800`: Larger chunks preserve context for procedures and specifications\n",
    "- `chunk_overlap=100`: Overlap ensures context continuity across chunk boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text using the utility function\n",
    "chunks = split_text(MANUAL_TEXT, chunk_size=800, chunk_overlap=100)\n",
    "\n",
    "print(f\"Split into {len(chunks)} chunks:\\n\")\n",
    "for i, chunk in enumerate(chunks[:5]):  # Show first 5 chunks\n",
    "    print(f\"Chunk {i}: {len(chunk)} chars\")\n",
    "    print(f\"  {chunk[:80]}...\\n\")\n",
    "\n",
    "if len(chunks) > 5:\n",
    "    print(f\"... and {len(chunks) - 5} more chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-chunks-intro",
   "metadata": {},
   "source": [
    "## Create Chunk Nodes\n",
    "\n",
    "Create Chunk nodes for each piece of text and link them to the Document with `FROM_DOCUMENT` relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-chunks-01",
   "metadata": {},
   "outputs": [],
   "source": "def create_chunks(driver, doc_element_id: str, chunks: list[str]) -> list[str]:\n    \"\"\"Create Chunk nodes linked to a Document. Returns chunk element IDs.\"\"\"\n    chunk_ids = []\n    for index, text in enumerate(chunks):\n        records, _, _ = driver.execute_query(\"\"\"\n            MATCH (d:Document) WHERE elementId(d) = $doc_id\n            CREATE (c:Chunk {text: $text, index: $index})\n            CREATE (c)-[:FROM_DOCUMENT]->(d)\n            RETURN elementId(c) as chunk_id\n        \"\"\", doc_id=doc_element_id, text=text, index=index)\n        chunk_id = records[0][\"chunk_id\"]\n        chunk_ids.append(chunk_id)\n        if index < 5 or index == len(chunks) - 1:\n            print(f\"Created Chunk {index}\")\n        elif index == 5:\n            print(\"...\")\n    return chunk_ids\n\nchunk_ids = create_chunks(driver, doc_element_id, chunks)\nprint(f\"\\nCreated {len(chunk_ids)} chunks\")"
  },
  {
   "cell_type": "markdown",
   "id": "link-chunks-intro",
   "metadata": {},
   "source": [
    "## Link Chunks with NEXT_CHUNK\n",
    "\n",
    "Create `NEXT_CHUNK` relationships between sequential chunks. This preserves the original document order for context retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "link-chunks-01",
   "metadata": {},
   "outputs": [],
   "source": "def link_chunks(driver, chunk_ids: list[str]):\n    \"\"\"Create NEXT_CHUNK relationships between sequential chunks.\"\"\"\n    for i in range(len(chunk_ids) - 1):\n        driver.execute_query(\"\"\"\n            MATCH (c1:Chunk) WHERE elementId(c1) = $id1\n            MATCH (c2:Chunk) WHERE elementId(c2) = $id2\n            CREATE (c1)-[:NEXT_CHUNK]->(c2)\n        \"\"\", id1=chunk_ids[i], id2=chunk_ids[i+1])\n    print(f\"Created {len(chunk_ids) - 1} NEXT_CHUNK relationships\")\n\nlink_chunks(driver, chunk_ids)"
  },
  {
   "cell_type": "markdown",
   "id": "verify-intro",
   "metadata": {},
   "source": [
    "## Verify the Graph Structure\n",
    "\n",
    "Query the graph to see what we created alongside the existing aircraft topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-01",
   "metadata": {},
   "outputs": [],
   "source": "def show_graph_structure(driver):\n    \"\"\"Display the Document-Chunk graph structure.\"\"\"\n    # Count chunks per document\n    records, _, _ = driver.execute_query(\"\"\"\n        MATCH (d:Document)\n        OPTIONAL MATCH (d)<-[:FROM_DOCUMENT]-(c:Chunk)\n        RETURN d.documentId as document_id, d.title as title, count(c) as chunks\n    \"\"\")\n    print(\"=== Document-Chunk Structure ===\")\n    for record in records:\n        print(f\"Document: {record['document_id']}\")\n        print(f\"  Title: {record['title']}\")\n        print(f\"  Chunks: {record['chunks']}\")\n    \n    # Show chunk chain sample\n    records, _, _ = driver.execute_query(\"\"\"\n        MATCH (c:Chunk)\n        WHERE c.index IS NOT NULL\n        OPTIONAL MATCH (c)-[:NEXT_CHUNK]->(next:Chunk)\n        RETURN c.index as idx, \n               substring(c.text, 0, 60) as text,\n               next.index as next_idx\n        ORDER BY c.index\n        LIMIT 5\n    \"\"\")\n    print(\"\\n=== Chunk Chain (first 5) ===\")\n    for record in records:\n        next_str = f\" -> Chunk {record['next_idx']}\" if record['next_idx'] is not None else \" (end)\"\n        print(f\"Chunk {record['idx']}: \\\"{record['text']}...\\\"{next_str}\")\n\nshow_graph_structure(driver)"
  },
  {
   "cell_type": "markdown",
   "id": "part2-intro",
   "metadata": {},
   "source": "---\n\n# Part 2: Adding Embeddings for Semantic Search\n\nNow that we have our Document-Chunk graph, we'll add embeddings to enable semantic search. Embeddings are numerical representations (vectors) of text that capture semantic meaning.\n\n```\n\"How to fix engine vibration\" -> [0.12, -0.45, 0.78, ...] (1024 dimensions)\n\"Troubleshooting vibration exceedance\" -> [0.11, -0.44, 0.77, ...] (similar vector!)\n```\n\nSimilar texts have similar embeddings, enabling **semantic search** - finding maintenance procedures by meaning rather than exact keywords."
  },
  {
   "cell_type": "markdown",
   "id": "embedder-intro",
   "metadata": {},
   "source": "## Initialize Embedder\n\nCreate an embedder using Databricks Foundation Model APIs. We use `databricks-bge-large-en` which produces 1024-dimensional vectors optimized for semantic search."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedder-01",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = get_embedder()\n",
    "print(f\"Embedder initialized: {embedder.model_id}\")\n",
    "print(f\"Embedding dimensions: {EMBEDDING_DIMENSIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gen-embed-intro",
   "metadata": {},
   "source": "## Generate and Store Embeddings\n\nGenerate an embedding vector for each chunk and store them in Neo4j using `upsert_vectors` from the neo4j-graphrag library. This batch-stores all embeddings in a single operation rather than updating nodes one at a time."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gen-embed-01",
   "metadata": {},
   "outputs": [],
   "source": "def generate_embeddings(embedder, chunk_ids: list[str], driver) -> list[list[float]]:\n    \"\"\"Generate embeddings for all chunks and batch-store them using upsert_vectors.\"\"\"\n    # Fetch all chunk texts in one query\n    records, _, _ = driver.execute_query(\"\"\"\n        MATCH (c:Chunk) WHERE elementId(c) IN $chunk_ids\n          AND c.index IS NOT NULL\n        RETURN elementId(c) as chunk_id, c.text as text\n        ORDER BY c.index\n    \"\"\", chunk_ids=chunk_ids)\n\n    # Generate embeddings with progress display\n    embeddings = []\n    for i, record in enumerate(records):\n        embedding = embedder.embed_query(record[\"text\"])\n        embeddings.append(embedding)\n        if i < 3 or i == len(records) - 1:\n            print(f\"Chunk {i}: Generated {len(embedding)}-dimensional embedding\")\n        elif i == 3:\n            print(f\"Processing {len(records) - 4} more chunks...\")\n\n    # Batch-store all embeddings using neo4j-graphrag's upsert_vectors\n    ordered_ids = [record[\"chunk_id\"] for record in records]\n    upsert_vectors(\n        driver=driver,\n        ids=ordered_ids,\n        embedding_property=\"embedding\",\n        embeddings=embeddings,\n    )\n    print(f\"\\nStored {len(embeddings)} embeddings via upsert_vectors\")\n    return embeddings\n\nembeddings = generate_embeddings(embedder, chunk_ids, driver)"
  },
  {
   "cell_type": "markdown",
   "id": "vector-index-intro",
   "metadata": {},
   "source": "## Create Vector Index\n\nCreate a vector index in Neo4j for efficient similarity search. The index uses cosine similarity to compare embeddings.\n\n> **Note:** `create_vector_index` defaults to `fail_if_exists=False`, so it's safe to re-run without manually dropping the index first."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vector-index-01",
   "metadata": {},
   "outputs": [],
   "source": "INDEX_NAME = \"maintenanceChunkEmbeddings\"\n\ncreate_vector_index(\n    driver=driver,\n    name=INDEX_NAME,\n    label=\"Chunk\",\n    embedding_property=\"embedding\",\n    dimensions=EMBEDDING_DIMENSIONS,\n    similarity_fn=\"cosine\"\n)\nprint(f\"Created vector index: {INDEX_NAME} ({EMBEDDING_DIMENSIONS} dimensions, cosine similarity)\")"
  },
  {
   "cell_type": "markdown",
   "id": "3tfocihtdl6",
   "source": "## Create Fulltext Index\n\nCreate a fulltext index on Chunk text for keyword-based search. This enables `HybridRetriever` in later notebooks, which combines vector similarity with traditional keyword matching.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "svj9l97wgbr",
   "source": "FULLTEXT_INDEX_NAME = \"maintenanceChunkText\"\n\ncreate_fulltext_index(\n    driver=driver,\n    name=FULLTEXT_INDEX_NAME,\n    label=\"Chunk\",\n    node_properties=[\"text\"]\n)\nprint(f\"Created fulltext index: {FULLTEXT_INDEX_NAME}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "search-intro",
   "metadata": {},
   "source": [
    "## Vector Similarity Search\n",
    "\n",
    "Now we can search for chunks that are semantically similar to a query. The search:\n",
    "1. Converts the query to an embedding\n",
    "2. Finds chunks with similar embedding vectors\n",
    "3. Returns results ranked by similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "search-01",
   "metadata": {},
   "outputs": [],
   "source": "def vector_search(driver, embedder, query: str, top_k: int = 3):\n    \"\"\"Search for chunks similar to the query.\"\"\"\n    # Generate query embedding\n    query_embedding = embedder.embed_query(query)\n    \n    records, _, _ = driver.execute_query(\"\"\"\n        CALL db.index.vector.queryNodes($index_name, $top_k, $embedding)\n        YIELD node, score\n        RETURN node.text as text, node.index as idx, score\n    \"\"\", index_name=INDEX_NAME, top_k=top_k, embedding=query_embedding)\n    \n    return records\n\n# Test search with a maintenance query\nquery = \"How do I troubleshoot engine vibration?\"\nprint(f\"Query: \\\"{query}\\\"\\n\")\nprint(\"=\" * 70)\n\nresults = vector_search(driver, embedder, query)\nfor i, record in enumerate(results):\n    print(f\"\\n[{i+1}] Score: {record['score']:.4f} (Chunk {record['idx']})\")\n    print(f\"    {record['text'][:250]}...\")"
  },
  {
   "cell_type": "markdown",
   "id": "compare-intro",
   "metadata": {},
   "source": [
    "## Compare Different Queries\n",
    "\n",
    "Try different maintenance queries to see how semantic search finds relevant procedures even with different wording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-01",
   "metadata": {},
   "outputs": [],
   "source": "queries = [\n    \"What are the EGT limits during takeoff?\",\n    \"How to detect bearing wear in the engine?\",\n    \"What causes hydraulic pressure loss?\",\n    \"When should I replace the fuel filter?\"\n]\n\nfor query in queries:\n    print(f\"\\nQuery: \\\"{query}\\\"\")\n    print(\"-\" * 60)\n    results = vector_search(driver, embedder, query, top_k=1)\n    if results:\n        record = results[0]\n        print(f\"Best match (score: {record['score']:.4f}):\")\n        print(f\"  {record['text'][:200]}...\")"
  },
  {
   "cell_type": "markdown",
   "id": "summary-01",
   "metadata": {},
   "source": "## Summary\n\nIn this notebook, you learned the complete data preparation pipeline for adding semantic search to your aircraft knowledge graph:\n\n**Part 1 - Graph Structure:**\n1. **Document-Chunk structure** - The maintenance manual is split into searchable chunks\n2. **FROM_DOCUMENT relationship** - Links chunks back to their source document\n3. **NEXT_CHUNK relationship** - Preserves the sequential order of chunks\n\n**Part 2 - Embeddings:**\n4. **Databricks BGE embeddings** - 1024-dimensional vectors that capture semantic meaning\n5. **Batch vector storage** - Using `upsert_vectors` from neo4j-graphrag for efficient storage\n6. **Vector index** - Enabling efficient similarity search with cosine similarity\n7. **Fulltext index** - Enabling keyword-based search for hybrid retrieval\n8. **Semantic search** - Finding maintenance procedures by meaning, not just keywords\n\nYour knowledge graph now combines:\n- **Structured data**: Aircraft -> System -> Component hierarchy from Lab 5\n- **Unstructured data**: Maintenance manual chunks with embeddings and fulltext indexing\n\n---\n\n**Next:** [GraphRAG Retrievers](04_graphrag_retrievers.ipynb) - Learn to use retrievers that combine vector search with graph traversal for context-aware answers about aircraft maintenance.\n\n**Optional:** [Hybrid Retrievers](05_hybrid_retrievers.ipynb) - Explore hybrid search that combines vector similarity with keyword matching."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "neo4j.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}