{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-01",
   "metadata": {},
   "source": [
    "# Aircraft ETL to Neo4j\n",
    "\n",
    "This notebook loads Aircraft, System, and Component data from Databricks Unity Catalog into Neo4j Aura using the Neo4j Spark Connector.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to read CSV data from Unity Catalog Volumes\n",
    "- How to transform tabular data for graph loading\n",
    "- How to write nodes and relationships using the Neo4j Spark Connector\n",
    "- How to verify data with Cypher queries from Databricks\n",
    "\n",
    "## Prerequisites\n",
    "- Neo4j Aura credentials from Lab 1\n",
    "- Access to the workshop Databricks cluster (with Neo4j Spark Connector installed)\n",
    "\n",
    "## Instructions\n",
    "1. Clone this notebook to your personal folder\n",
    "2. Enter your Neo4j credentials in the Configuration cell below\n",
    "3. Run all cells in order (Shift+Enter or Run All)\n",
    "4. Verify the results in the final cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1-header",
   "metadata": {},
   "source": [
    "## Section 1: Configuration\n",
    "\n",
    "Enter your Neo4j Aura connection details below. You received these credentials when you created your Neo4j Aura instance in Lab 1."
   ]
  },
  {
   "cell_type": "code",
   "id": "config-credentials",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ============================================\n# CONFIGURATION - Enter your Neo4j credentials\n# ============================================\n\nNEO4J_URI = \"\"  # e.g., \"neo4j+s://xxxxxxxx.databases.neo4j.io\"\nNEO4J_USERNAME = \"neo4j\"\nNEO4J_PASSWORD = \"\"  # Your password from Lab 1\n\n# Unity Catalog Volume path (pre-configured by workshop admin)\nDATA_PATH = \"/Volumes/aws-databricks-neo4j-lab/lab-schema/lab-volume\"\n\n# Validate configuration\nif not NEO4J_URI or not NEO4J_PASSWORD:\n    print(\"WARNING: Please enter your Neo4j credentials above before running the notebook!\")\nelse:\n    print(\"Configuration ready!\")\n    print(f\"Neo4j URI: {NEO4J_URI}\")\n    print(f\"Data Path: {DATA_PATH}\")"
  },
  {
   "cell_type": "code",
   "id": "config-spark",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configure Neo4j Spark Connector\n",
    "spark.conf.set(\"neo4j.url\", NEO4J_URI)\n",
    "spark.conf.set(\"neo4j.authentication.basic.username\", NEO4J_USERNAME)\n",
    "spark.conf.set(\"neo4j.authentication.basic.password\", NEO4J_PASSWORD)\n",
    "spark.conf.set(\"neo4j.database\", \"neo4j\")\n",
    "\n",
    "print(\"Spark configured for Neo4j connection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-header",
   "metadata": {},
   "source": [
    "## Section 2: Data Preview\n",
    "\n",
    "Let's examine the CSV files that we'll load into Neo4j. The data represents an Aircraft Digital Twin with three entity types:\n",
    "\n",
    "- **Aircraft**: Fleet of 20 aircraft with tail numbers, models, and operators\n",
    "- **System**: Major systems on each aircraft (engines, avionics, hydraulics)\n",
    "- **Component**: Parts within each system (fans, compressors, turbines, etc.)\n",
    "\n",
    "The graph structure will be:\n",
    "```\n",
    "(Aircraft) -[:HAS_SYSTEM]-> (System) -[:HAS_COMPONENT]-> (Component)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "helper-read-csv",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper function to read CSV files\n",
    "def read_csv(filename):\n",
    "    \"\"\"Read a CSV file from the Unity Catalog Volume.\"\"\"\n",
    "    path = f\"{DATA_PATH}/{filename}\"\n",
    "    return spark.read.option(\"header\", \"true\").csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "id": "load-csv-files",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read all CSV files\n",
    "aircraft_df = read_csv(\"nodes_aircraft.csv\")\n",
    "systems_df = read_csv(\"nodes_systems.csv\")\n",
    "components_df = read_csv(\"nodes_components.csv\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA LOADED FROM UNITY CATALOG\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Aircraft:   {aircraft_df.count()} rows\")\n",
    "print(f\"Systems:    {systems_df.count()} rows\")\n",
    "print(f\"Components: {components_df.count()} rows\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preview-aircraft-header",
   "metadata": {},
   "source": [
    "### Aircraft Data\n",
    "\n",
    "Each aircraft has a unique ID, tail number, model, manufacturer, and operator."
   ]
  },
  {
   "cell_type": "code",
   "id": "preview-aircraft",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(aircraft_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preview-systems-header",
   "metadata": {},
   "source": [
    "### Systems Data\n",
    "\n",
    "Each system belongs to an aircraft (via `aircraft_id`) and has a type (Engine, Avionics, Hydraulics)."
   ]
  },
  {
   "cell_type": "code",
   "id": "preview-systems",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(systems_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preview-components-header",
   "metadata": {},
   "source": [
    "### Components Data\n",
    "\n",
    "Each component belongs to a system (via `system_id`) and has a type (Fan, Compressor, Turbine, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "id": "preview-components",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(components_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3-header",
   "metadata": {},
   "source": [
    "## Section 3: Load Nodes to Neo4j\n",
    "\n",
    "Now we'll write the data to Neo4j as graph nodes. The Neo4j Spark Connector writes DataFrames directly to Neo4j.\n",
    "\n",
    "**Key Concepts:**\n",
    "- Each DataFrame row becomes a node\n",
    "- Column values become node properties\n",
    "- The `labels` option sets the node label (e.g., `:Aircraft`)\n",
    "- The `node.keys` option identifies the unique key property"
   ]
  },
  {
   "cell_type": "code",
   "id": "helper-write-nodes",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper function to write nodes\n",
    "def write_nodes(df, label, id_column):\n",
    "    \"\"\"Write a DataFrame as nodes to Neo4j.\"\"\"\n",
    "    (df\n",
    "     .write\n",
    "     .format(\"org.neo4j.spark.DataSource\")\n",
    "     .mode(\"Overwrite\")\n",
    "     .option(\"labels\", f\":{label}\")\n",
    "     .option(\"node.keys\", id_column)\n",
    "     .save())\n",
    "    count = df.count()\n",
    "    print(f\"Wrote {count} {label} nodes to Neo4j\")\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-aircraft-header",
   "metadata": {},
   "source": [
    "### Transform and Load Aircraft Nodes"
   ]
  },
  {
   "cell_type": "code",
   "id": "transform-aircraft",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transform: Rename the ID column from Neo4j import format to standard name\n",
    "aircraft_clean = aircraft_df.withColumnRenamed(\":ID(Aircraft)\", \"aircraft_id\")\n",
    "\n",
    "# Show the transformed schema\n",
    "print(\"Aircraft schema:\")\n",
    "aircraft_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "id": "load-aircraft",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write Aircraft nodes to Neo4j\n",
    "aircraft_count = write_nodes(aircraft_clean, \"Aircraft\", \"aircraft_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-systems-header",
   "metadata": {},
   "source": [
    "### Transform and Load System Nodes"
   ]
  },
  {
   "cell_type": "code",
   "id": "load-systems",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transform System data\n",
    "systems_clean = systems_df.withColumnRenamed(\":ID(System)\", \"system_id\")\n",
    "\n",
    "# Write System nodes to Neo4j\n",
    "systems_count = write_nodes(systems_clean, \"System\", \"system_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-components-header",
   "metadata": {},
   "source": [
    "### Transform and Load Component Nodes"
   ]
  },
  {
   "cell_type": "code",
   "id": "load-components",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transform Component data\n",
    "components_clean = components_df.withColumnRenamed(\":ID(Component)\", \"component_id\")\n",
    "\n",
    "# Write Component nodes to Neo4j\n",
    "components_count = write_nodes(components_clean, \"Component\", \"component_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4-header",
   "metadata": {},
   "source": [
    "## Section 4: Load Relationships to Neo4j\n",
    "\n",
    "Now we'll create the relationships that connect our nodes:\n",
    "- `HAS_SYSTEM`: Connects Aircraft to their Systems\n",
    "- `HAS_COMPONENT`: Connects Systems to their Components\n",
    "\n",
    "**Key Concepts:**\n",
    "- The `relationship` option specifies the relationship type\n",
    "- The `relationship.save.strategy` of `keys` matches nodes by their key properties\n",
    "- Source and target labels/keys identify which nodes to connect"
   ]
  },
  {
   "cell_type": "code",
   "id": "helper-write-rels",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper function to write relationships\n",
    "def write_relationships(df, rel_type, source_label, source_key, target_label, target_key):\n",
    "    \"\"\"Write relationships to Neo4j using keys strategy.\"\"\"\n",
    "    (df\n",
    "     .write\n",
    "     .format(\"org.neo4j.spark.DataSource\")\n",
    "     .mode(\"Overwrite\")\n",
    "     .option(\"relationship\", rel_type)\n",
    "     .option(\"relationship.save.strategy\", \"keys\")\n",
    "     .option(\"relationship.source.labels\", f\":{source_label}\")\n",
    "     .option(\"relationship.source.node.keys\", source_key)\n",
    "     .option(\"relationship.target.labels\", f\":{target_label}\")\n",
    "     .option(\"relationship.target.node.keys\", target_key)\n",
    "     .save())\n",
    "    count = df.count()\n",
    "    print(f\"Wrote {count} {rel_type} relationships to Neo4j\")\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-has-system-header",
   "metadata": {},
   "source": [
    "### Load HAS_SYSTEM Relationships\n",
    "\n",
    "Connect each Aircraft to its Systems."
   ]
  },
  {
   "cell_type": "code",
   "id": "transform-has-system",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read and transform relationship data\n",
    "aircraft_system_df = read_csv(\"rels_aircraft_system.csv\")\n",
    "\n",
    "# Rename columns to match our node keys\n",
    "aircraft_system_clean = (aircraft_system_df\n",
    "    .withColumnRenamed(\":START_ID(Aircraft)\", \"aircraft_id\")\n",
    "    .withColumnRenamed(\":END_ID(System)\", \"system_id\"))\n",
    "\n",
    "print(\"HAS_SYSTEM relationship data:\")\n",
    "display(aircraft_system_clean.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "id": "load-has-system",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write HAS_SYSTEM relationships\n",
    "has_system_count = write_relationships(\n",
    "    aircraft_system_clean,\n",
    "    \"HAS_SYSTEM\",\n",
    "    \"Aircraft\", \"aircraft_id\",\n",
    "    \"System\", \"system_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-has-component-header",
   "metadata": {},
   "source": [
    "### Load HAS_COMPONENT Relationships\n",
    "\n",
    "Connect each System to its Components."
   ]
  },
  {
   "cell_type": "code",
   "id": "transform-has-component",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read and transform relationship data\n",
    "system_component_df = read_csv(\"rels_system_component.csv\")\n",
    "\n",
    "# Rename columns to match our node keys\n",
    "system_component_clean = (system_component_df\n",
    "    .withColumnRenamed(\":START_ID(System)\", \"system_id\")\n",
    "    .withColumnRenamed(\":END_ID(Component)\", \"component_id\"))\n",
    "\n",
    "print(\"HAS_COMPONENT relationship data:\")\n",
    "display(system_component_clean.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "id": "load-has-component",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write HAS_COMPONENT relationships\n",
    "has_component_count = write_relationships(\n",
    "    system_component_clean,\n",
    "    \"HAS_COMPONENT\",\n",
    "    \"System\", \"system_id\",\n",
    "    \"Component\", \"component_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etl-complete-header",
   "metadata": {},
   "source": [
    "## ETL Complete!\n",
    "\n",
    "Summary of data loaded to Neo4j:"
   ]
  },
  {
   "cell_type": "code",
   "id": "etl-summary",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ETL COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"NODES LOADED:\")\n",
    "print(f\"  Aircraft:   {aircraft_count}\")\n",
    "print(f\"  System:     {systems_count}\")\n",
    "print(f\"  Component:  {components_count}\")\n",
    "print(f\"  ---------------------\")\n",
    "print(f\"  Total:      {aircraft_count + systems_count + components_count}\")\n",
    "print()\n",
    "print(\"RELATIONSHIPS LOADED:\")\n",
    "print(f\"  HAS_SYSTEM:    {has_system_count}\")\n",
    "print(f\"  HAS_COMPONENT: {has_component_count}\")\n",
    "print(f\"  ---------------------\")\n",
    "print(f\"  Total:         {has_system_count + has_component_count}\")\n",
    "print()\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5-header",
   "metadata": {},
   "source": [
    "## Section 5: Verification Queries\n",
    "\n",
    "Let's verify the data loaded correctly by running Cypher queries from Databricks."
   ]
  },
  {
   "cell_type": "code",
   "id": "helper-run-cypher",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper function to run Cypher queries\n",
    "def run_cypher(query):\n",
    "    \"\"\"Execute a Cypher query and return results as DataFrame.\"\"\"\n",
    "    return (spark.read\n",
    "        .format(\"org.neo4j.spark.DataSource\")\n",
    "        .option(\"query\", query)\n",
    "        .load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-nodes-header",
   "metadata": {},
   "source": [
    "### Verify Node Counts"
   ]
  },
  {
   "cell_type": "code",
   "id": "verify-nodes",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Node counts by label:\")\n",
    "result = run_cypher(\"\"\"\n",
    "    MATCH (n)\n",
    "    RETURN labels(n)[0] AS NodeType, count(*) AS Count\n",
    "    ORDER BY NodeType\n",
    "\"\"\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-rels-header",
   "metadata": {},
   "source": [
    "### Verify Relationship Counts"
   ]
  },
  {
   "cell_type": "code",
   "id": "verify-rels",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Relationship counts by type:\")\n",
    "result = run_cypher(\"\"\"\n",
    "    MATCH ()-[r]->()\n",
    "    RETURN type(r) AS RelType, count(*) AS Count\n",
    "    ORDER BY RelType\n",
    "\"\"\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-hierarchy-header",
   "metadata": {},
   "source": [
    "### Sample Query: Aircraft Hierarchy\n",
    "\n",
    "View the complete hierarchy for aircraft N95040A (a Boeing 737-800)."
   ]
  },
  {
   "cell_type": "code",
   "id": "sample-hierarchy",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = run_cypher(\"\"\"\n",
    "    MATCH (a:Aircraft {tail_number: 'N95040A'})-[:HAS_SYSTEM]->(s:System)\n",
    "    OPTIONAL MATCH (s)-[:HAS_COMPONENT]->(c:Component)\n",
    "    RETURN a.tail_number AS Aircraft,\n",
    "           a.model AS Model,\n",
    "           s.name AS System,\n",
    "           s.type AS SystemType,\n",
    "           collect(c.name) AS Components\n",
    "    ORDER BY s.type, s.name\n",
    "\"\"\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-fleet-header",
   "metadata": {},
   "source": [
    "### Sample Query: Fleet by Manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "id": "sample-fleet",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = run_cypher(\"\"\"\n",
    "    MATCH (a:Aircraft)\n",
    "    RETURN a.manufacturer AS Manufacturer,\n",
    "           count(a) AS AircraftCount,\n",
    "           collect(a.model) AS Models\n",
    "    ORDER BY AircraftCount DESC\n",
    "\"\"\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-components-header",
   "metadata": {},
   "source": [
    "### Sample Query: Component Distribution"
   ]
  },
  {
   "cell_type": "code",
   "id": "sample-components",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = run_cypher(\"\"\"\n",
    "    MATCH (c:Component)\n",
    "    RETURN c.type AS ComponentType, count(c) AS Count\n",
    "    ORDER BY Count DESC\n",
    "\"\"\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6-header",
   "metadata": {},
   "source": "## Section 6: Next Steps - Explore in Neo4j Aura\n\nNow that the data is loaded, open your Neo4j Aura console to visualize the graph!\n\n### How to Access Neo4j Aura\n1. Go to [console.neo4j.io](https://console.neo4j.io)\n2. Sign in with your Neo4j account\n3. Click on your instance\n4. Click **Query** to open the query interface\n\n### Visualization Queries to Try\n\n**See one aircraft's complete hierarchy:**\n```cypher\nMATCH (a:Aircraft {tail_number: 'N95040A'})-[r1:HAS_SYSTEM]->(s:System)-[r2:HAS_COMPONENT]->(c:Component)\nRETURN a, r1, s, r2, c\n```\n\n**Compare aircraft by operator:**\n```cypher\nMATCH (a:Aircraft)\nRETURN a.operator AS Operator, count(a) AS Count\n```\n\n**Find all engine components:**\n```cypher\nMATCH (s:System {type: 'Engine'})-[:HAS_COMPONENT]->(c:Component)\nRETURN c.type AS ComponentType, count(c) AS Count\nORDER BY Count DESC\n```\n\n### Exploration Tips\n- Click on nodes in the visualization to see their properties\n- Double-click to expand connected nodes\n- Use the styling panel to color nodes by property (e.g., manufacturer)"
  },
  {
   "cell_type": "markdown",
   "id": "congrats",
   "metadata": {},
   "source": "## Congratulations!\n\nYou have successfully:\n- Read CSV data from Databricks Unity Catalog\n- Transformed tabular data for graph loading\n- Written nodes and relationships to Neo4j using the Spark Connector\n- Verified the data with Cypher queries\n\n**Next:** Open `02_load_neo4j_full` to load the complete dataset (Sensors, Flights, Airports, Delays, Maintenance Events, Removals) required for Lab 7."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}