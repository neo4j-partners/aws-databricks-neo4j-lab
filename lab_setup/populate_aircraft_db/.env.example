# ── Neo4j connection (required) ──────────────────────────────────────────────
NEO4J_URI=neo4j+s://xxxxxxxx.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password-here

# ── LLM provider for entity extraction (enrich command) ─────────────────────
# Choose "openai" (default) or "anthropic"
LLM_PROVIDER=openai

# ── OpenAI (required for enrich) ────────────────────────────────────────────
# Embeddings always use OpenAI; LLM extraction uses OpenAI when LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# OPENAI_EMBEDDING_DIMENSIONS=1536
#
# Extraction model — used for entity extraction from maintenance manuals.
# Available models (see https://platform.openai.com/docs/models):
#
#   gpt-5.2        — Flagship model. Best for coding and agentic tasks. Most capable.
#   gpt-5.2-pro    — Extended-thinking variant of GPT-5.2 for complex reasoning.
#   gpt-5-mini     — Fast, cost-effective. Good balance of quality and speed. (default)
#   gpt-5-nano     — Smallest and cheapest. Best for high-volume, simple tasks.
#
# Embedding models (for OPENAI_EMBEDDING_MODEL):
#   text-embedding-3-small  — Fast, affordable embeddings (default)
#   text-embedding-3-large  — Most capable embeddings for English and multilingual
#
# OPENAI_EXTRACTION_MODEL=gpt-5-mini

# ── Anthropic (required for enrich when LLM_PROVIDER=anthropic) ─────────────
# Install with: uv sync --extra anthropic
# ANTHROPIC_API_KEY=sk-ant-your-key-here
# ANTHROPIC_EXTRACTION_MODEL=claude-sonnet-4-6-20260217

# ── Chunking (enrich command) ───────────────────────────────────────────────
# Controls how maintenance manuals are split into chunks before embedding
# CHUNK_SIZE=800
# CHUNK_OVERLAP=100

# Limit chunks processed per document (0 = no limit, process all).
# Set to a small number (e.g. 10) for quick test runs.
# ENRICH_SAMPLE_SIZE=0

# ── Samples (samples command) ───────────────────────────────────────────────
# Number of rows returned per section when running sample queries
# SAMPLE_SIZE=10
